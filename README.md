# [Generative AI with Large Language Models](https://www.deeplearning.ai/courses/generative-ai-with-llms/)
In the course on Generative AI with Large Language Models (LLMs), you'll gain a fundamental understanding of how generative AI operates and how to implement it in practical applications.

By taking this course, you'll learn to:
- Gain a thorough understanding of generative AI and the key steps in the LLM lifecycle, including data gathering, model selection, performance evaluation, and deployment.
- Explain the transformer architecture, its training process, and how fine-tuning adapts LLMs to specific use cases.
- Optimize the model's objective function using empirical scaling laws considering dataset size, compute budget, and inference requirements.
- Implement advanced training, tuning, inference, tools, and deployment methods to enhance model performance within project constraints.
- Explore the challenges and opportunities of generative AI in business through insights from industry researchers and practitioners.


## Week 1
Generative AI use cases, project lifecycle, and model pre-training

### Learning Objectives
- Explore model pre-training and evaluate the benefits of ongoing pre-training compared to fine-tuning.
- Clarify the terms Generative AI, large language models, and prompt, and explain the transformer architecture that drives LLMs.
- Detail the stages of a generative AI model lifecycle using LLMs and examine the constraints that influence decisions at each stage.
- Address the computational challenges encountered during model pre-training and identify methods to efficiently minimize memory usage.
- Define scaling laws and explain the laws related to LLMs concerning training dataset size, compute budget, inference requirements, and other factors.

[Lab 1 - Generative AI Use Case: Summarize Dialogue](https://github.com/zanvari/Generative-AI-with-Large-Language-Models/blob/main/Week_1/Lab_1_summarize_dialogue.ipynb)

[Week 1 quiz](https://github.com/zanvari/Generative-AI with-Large-Language-Models/blob/main/Week_1/Week_1_Quiz.md)

## Week 2
Fine-tuning and evaluating large language models

### Learning Objectives
- Explain how fine-tuning with instruction-based prompt datasets can enhance performance on multiple tasks.
- Define catastrophic forgetting and discuss strategies to mitigate it.
- Define Parameter-efficient Fine Tuning (PEFT).
- Describe how PEFT reduces computational costs and addresses catastrophic forgetting.
- Discuss how instruction-based prompt dataset fine-tuning can improve LLM performance on various tasks.

[Lab 2 - Fine-tune a generative AI model for dialogue summarization](https://github.com/zanvari/Generative-AI with-Large-Language-Models/blob/main/Week_2/Lab_2_fine_tune_generative_ai_model.ipynb)

[Week 2 quiz](https://github.com/zanvari/Generative-AI with-Large-Language-Models/blob/main/Week_2/Week_2_Quiz.md)

## Week 3
Reinforcement learning and LLM-powered applications

### Learning Objectives
- Explain how RLHF leverages human feedback to enhance the performance and alignment of large language models.
- Detail how data collected from human labelers is utilized to train a reward model for RLHF.
- Define chain-of-thought prompting and describe its role in enhancing LLMs' reasoning and planning capabilities.
- Discuss the challenges LLMs encounter due to knowledge cut-offs and explain how information retrieval and augmentation methods can address these issues.

[Lab 3 - Fine-tune FLAN-T5 with reinforcement learning to generate more-positive summaries](https://github.com/zanvari/Generative-AI with-Large-Language-Models/blob/main/Week_3/Lab_3_fine_tune_model_to_detoxify_summaries.ipynb)

[Week 3 Quiz](https://github.com/zanvari/Generative-AI with-Large-Language-Models/blob/main/Week_3/Week_3_Quiz.md)
